{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2/pvuGr33QVmKRo+wwZOF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tushar4221/First-Repo/blob/main/Untitled19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from joblib import dump\n",
        "from sklearn import svm, tree\n",
        "import pdb\n",
        "\n",
        "\n",
        "def get_all_combs(param_vals, param_name, combs_so_far):\n",
        "    new_combs_so_far = []        \n",
        "    for c in combs_so_far:        \n",
        "        for v in param_vals:\n",
        "            cc = c.copy()\n",
        "            cc[param_name] = v\n",
        "            new_combs_so_far.append(cc)\n",
        "    return new_combs_so_far\n",
        "\n",
        "\n",
        "def get_all_h_param_comb(params):\n",
        "    h_param_comb = [{}]\n",
        "    for p_name in params:\n",
        "        h_param_comb = get_all_combs(\n",
        "            param_vals=params[p_name], param_name=p_name, combs_so_far=h_param_comb\n",
        "        )\n",
        "\n",
        "    return h_param_comb\n",
        "\n",
        "\n",
        "def preprocess_digits(dataset):\n",
        "    n_samples = len(dataset.images)\n",
        "    data = dataset.images.reshape((n_samples, -1))\n",
        "    label = dataset.target\n",
        "    return data, label\n",
        "\n",
        "#viz\n",
        "def data_viz(dataset):\n",
        "    _, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "    for ax, image, label in zip(axes, dataset.images, dataset.target):\n",
        "        ax.set_axis_off()\n",
        "        ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "        ax.set_title(\"Training: %i\" % label)\n",
        "\n",
        "\n",
        "#Predect\n",
        "def pred_image_viz(x_test, predictions):\n",
        "    _, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "    for ax, image, prediction in zip(axes, x_test, predictions):\n",
        "        ax.set_axis_off()\n",
        "        image = image.reshape(8, 8)\n",
        "        ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "        ax.set_title(f\"Prediction: {prediction}\")\n",
        "\n",
        "\n",
        "#Train test\n",
        "\n",
        "\n",
        "def train_dev_test_split(data, label, train_frac, dev_frac):\n",
        "\n",
        "    dev_test_frac = 1 - train_frac\n",
        "    x_train, x_dev_test, y_train, y_dev_test = train_test_split(\n",
        "        data, label, test_size=dev_test_frac, shuffle=True\n",
        "    )\n",
        "    x_test, x_dev, y_test, y_dev = train_test_split(\n",
        "        x_dev_test, y_dev_test, test_size=(dev_frac) / dev_test_frac, shuffle=True\n",
        "    )\n",
        "\n",
        "    return x_train, y_train, x_dev, y_dev, x_test, y_test\n",
        "\n",
        "\n",
        "def h_param_tuning(h_param_comb, clf, x_train, y_train, x_dev, y_dev, metric, verbose=False):\n",
        "    best_metric = -1.0\n",
        "    best_model = None\n",
        "    best_h_params = None\n",
        "    # 2. H-Values\n",
        "    for cur_h_params in h_param_comb:\n",
        "\n",
        "     \n",
        "        hyper_params = cur_h_params\n",
        "        clf.set_params(**hyper_params)\n",
        "\n",
        "        #Train model\n",
        "      \n",
        "        clf.fit(x_train, y_train)\n",
        "\n",
        "        #predictions\n",
        "        predicted_dev = clf.predict(x_dev)\n",
        "\n",
        "        # Acc on prediction \n",
        "        cur_metric = metric(y_pred=predicted_dev, y_true=y_dev)\n",
        "\n",
        "        if cur_metric > best_metric:\n",
        "            best_metric = cur_metric\n",
        "            best_model = clf\n",
        "            best_h_params = cur_h_params\n",
        "            if verbose:\n",
        "                print(\"best metric :\" + str(cur_h_params))\n",
        "                print(\"New best val metric:\" + str(cur_metric))\n",
        "    return best_model, best_metric, best_h_params\n",
        "\n",
        "\n",
        "def tune_and_save(\n",
        "    clf, x_train, y_train, x_dev, y_dev, metric, h_param_comb, model_path\n",
        "):\n",
        "    best_model, best_metric, best_h_params = h_param_tuning(\n",
        "        h_param_comb, clf, x_train, y_train, x_dev, y_dev, metric\n",
        "    )\n",
        "\n",
        "    # best_model\n",
        "    best_param_config = \"_\".join(\n",
        "        [h + \"=\" + str(best_h_params[h]) for h in best_h_params]\n",
        "    )\n",
        "\n",
        "    if type(clf) == svm.SVC:\n",
        "        model_type = \"svm\"\n",
        "\n",
        "    if type(clf) == tree.DecisionTreeClassifier:\n",
        "        model_type = \"decision_tree\"\n",
        "\n",
        "    best_model_name = model_type + \"_\" + best_param_config + \".joblib\"\n",
        "    if model_path == None:\n",
        "        model_path = best_model_name\n",
        "    dump(best_model, model_path)\n",
        "\n",
        "    print(\"Final hyperparameter:\" + str(best_h_params))\n",
        "\n",
        "    print(\"Best Metric:{}\".format(best_metric))\n",
        "\n",
        "    return model_path\n",
        "\n",
        "\n",
        "def macro_f1(y_true, y_pred, pos_label=1):\n",
        "    return f1_score(y_true, y_pred, pos_label=pos_label, average='macro', zero_division='warn')"
      ],
      "metadata": {
        "id": "XzjGqJAoGn2-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}